## Extreme Multimodality
- Video Understanding with Large Language Models: A Survey
- Audio-Visual LLM for Video Understanding
- Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding
- **Compression on the video representation**
  - INFERENCE OPTIMAL VLMS NEED ONLY ONE VISUAL TOKEN BUT LARGER MODELS
  - LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token 
## Efficent Long-Video Serving
- ZipVL: Efficient Large Vision-Language Models with Dynamic Token
Sparsification
- Cachegen: Kv cache compression and streaming for fast large language model serving
