# Papers List
List of Papers to Read  

**Model papers**
- genie 1 genie 2 (google deepmind) **DONE**
- Olmoe (mixture of experts one)
- Molmo (multimodal one) **DONE**
- RoPE **DONE**
- ViT paper (review) **DONE**
- ViVit: a video transformer model
- DeepSeek-V3 Technical Report

**VLM Architeciture**
- Apollo: An Exploration of Video Understanding in Large Multimodal Models **DONE**
- LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One   Vision Token 
- INFERENCE OPTIMAL VLMS NEED ONLY ONE VISUAL TOKEN BUT LARGER MODELS

**Training scaling**

- Megatron-LM **DONE**
- pytorch FSDP
- multi query attn (MQA) **DONE**
- grouped query attn (GQA) **DONE**
- Ring Attn (review?)
- Longformer
- LongNet

**Data**
- Best Practices and Lessons Learned on Synthetic Data (COLM 2024)

**Inference**  

Maybe do a project on training long context video LLMs + fast inference technqiues to get real time video processing?
Basic Quantization techniques
- GPTQ
- LLM.int8()

KV Caching and model serving
- long context serving https://arxiv.org/pdf/2405.08944
- more kv caching stuff (?)
